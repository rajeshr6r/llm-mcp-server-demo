# LLM - MCP - Server - Demo

## Project Structure
  - [ ] Local LLM Server 
    - [ ] Ollama
    - [ ] llama3.2 model setup
    - [ ] RAG emulation to let the model talk to MCP server for product recommendations 
  - [ ] Open Web UI
  - [ ] MCP Server
    - [ ]   Python FastAPI Server
    - [ ]   SQL DB
    - [ ]   Product catalogue


